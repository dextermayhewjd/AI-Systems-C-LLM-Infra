主要提到了几点
#  多核带来的收益 取决于算法本身 p48 
#### 运算图值得注意 slides 43
#### 功率墙问题 p
####  parallel + special hardware
# 是cache 是否命中带来的速度提升
	- Direct mapped cache
	- Set-associative cache
	- Cache line
   LRU replacement policy (“least recently used”)

Spatial locality: loading data in a cache line “preloads” the
data needed for subsequent accesses to diﬀerent addresses
in the same line, leading to cache hits
获取缓存中的数据 预先load 加载数据， 致使cache hit

Temporal locality: repeated accesses to the same address
result in hits.
反复访问统一缓存

# 数据移动带来的电量消耗 
	Data movement has high energy cost
	▪ Rule of thumb in modern system design: always seek to reduce amount of data movement in a computer
	▪ “Ballpark” numbers
	- Integer op: ~ 1 pJ *
	- Floating point op: ~20 pJ *
	- Reading 64 bits from small local SRAM (1mm away on chip): ~ 26 pJ
	- Reading 64 bits from low power mobile DRAM (LPDDR): ~1200 pJ
	▪ Implications
	- Reading 10 GB/sec from memory: ~1.6 watts
	- Entire power budget for mobile GPU: ~1 watt
	(remember phone is also running CPU, display, radios, etc.)
	- iPhone 6 battery: ~7 watt-hours (note: my Macbook Pro laptop: 99 watt-hour battery)
	- Exploiting locality matters!!!